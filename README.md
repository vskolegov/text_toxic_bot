# text_toxic_bot — локальный Telegram-бот для детекции токсичности речи

Полный боевой README для развёртывания и разработки проекта локально.

## Описание

`text_toxic_bot` — проект на Python, реализующий два способа инференса токсичности речи:
- классические модели (TF‑IDF + LogisticRegression/SVM и ансамбль)
- BiLSTM (PyTorch checkpoint)

Бот принимает голосовые сообщения, конвертирует их в WAV (через `ffmpeg`), запускает локальную модель распознавания речи (Whisper) и затем передаёт текст на предсказание модели токсичности. Также есть локальный HTTP endpoint `/predict` (FastAPI) для интеграции.

Проект ориентирован на локальную работу (без облачных сервисов) и предназначен для исследовательских/демонстрационных целей.

## Структура репозитория (важные файлы)

- text_toxic_bot: основной пакет с ботом, инференсом и моделями
  - `text_toxic_bot/bot.py` — асинхронный Telegram‑бот (PTB v20+)
  - `text_toxic_bot/inference.py` — точка входа для `predict_toxicity(text, model_type)`
  - `text_toxic_bot/models/` — локальные файлы моделей (пиклы, `.pth`, словари)
  - `text_toxic_bot/data/` — вспомогательные JSON (пользователи, настройки)
  - `text_toxic_bot/requirements.txt` — зависимости (проверить версии!)

## Требования

- Python 3.10+
- `ffmpeg` доступен в PATH (нужен для конвертации ogg → wav)
- Свободное место для моделей (Whisper загружает веса при первом запуске, несколько сотен мегабайт)

Python-зависимости указаны в `text_toxic_bot/requirements.txt`. Примеры ключевых библиотек:

- python-telegram-bot (v20+ / рекомендуем >=22)
- torch
- openai-whisper
- scikit-learn
- fastapi, uvicorn

Перед установкой рекомендуем создать виртуальное окружение:

```bash
python -m venv .venv
source .venv/bin/activate    # Windows: .venv\Scripts\activate
pip install -U pip
pip install -r text_toxic_bot/requirements.txt
```

Если сталкиваетесь с конфликтами версий (особенно `python-telegram-bot`), приведите зависимости к согласованным версиям. Репозиторий использует PTB v20+ async API.

## Конфигурация

1. Создайте файл `.env` в каталоге `text_toxic_bot/` с переменной `TELEGRAM_TOKEN`:

```
TELEGRAM_TOKEN=123456:ABC-DEF...
```

2. Если используете прокси, экспортируйте переменные окружения `HTTP_PROXY` / `HTTPS_PROXY` или настройте систему прокси отдельно.

> ВНИМАНИЕ: не храните рабочие токены в репозитории. Удалите `.env` из индекса и добавьте в `.gitignore`.

## Запуск

1) Запуск Telegram‑бота (локально)

```bash
cd text_toxic_bot
python -m text_toxic_bot.bot
```

Бот использует асинхронные обработчики и для тяжёлых задач (Whisper, инференс BiLSTM, ffmpeg) переводит работу в `run_in_executor`, чтобы не блокировать loop.

2) Запуск FastAPI endpoint (если включён)

```bash
uvicorn text_toxic_bot.api:app --reload --port 8000
```

Эндпойнт `/predict` принимает JSON: `{ "text": "...", "model": "classic" }` и возвращает результат предсказания.

## Использование бота

- /start — стартовое сообщение и клавиатура
- Выбор модели — кнопки на клавиатуре (`Ансамбль`, `BiLSTM`, `Classic`, и т.д.)
- Отправьте голосовое сообщение — бот транскрибирует его и вернёт метку и вероятности. Метка выводится текстом: "токсично" / "не токсично".

Клавиатура также содержит кнопку "Инфо моделей" — показывает краткую информацию о загруженных моделях и их источниках.

## Модели

Модели лежат в `text_toxic_bot/models/`:

- classic: `tfidf.pkl`, `model_logreg.pkl`, `model_svm.pkl`, и т.д.
- bilstm: `correct_bilstm.pth`, `word2idx.pkl`

Код реализует ленивую загрузку: модели загружаются при первом вызове `predict_toxicity`. Это удобно для экономии памяти при старте.

Если вы заменяете файлы моделей, убедитесь, что форматы совпадают и что используемые версии библиотек (scikit-learn, torch) совместимы с файлами.

## Рекомендации по безопасности и развёртыванию

- Никогда не коммитите `.env` с рабочими токенами. Выполните `git rm --cached text_toxic_bot/.env` и добавьте правило в `.gitignore`.
- Не храните большие веса моделей в репозитории. Лучше держать веса в отдельном артефакте/облачном хранилище и загружать их в CI/CD.
- Пиньте версии зависимостей — особенно PTB и torch.

## Отладка и часто встречающиеся проблемы

- Ошибка с инициализацией PTB `ExtBot` / сетевые таймауты: проверьте корректность `TELEGRAM_TOKEN` и настройки прокси/фаервола.
- Ошибки при распаковке pickle (scikit-learn): возможно несоответствие версии `scikit-learn` при создании и загрузке модели. Попробуйте установить ту же версию, что и использовавшаяся при тренировке.
- Whisper скачивает веса при первом запуске — убедитесь, что есть место и стабильное соединение.
- `ffmpeg` не найден: установите `ffmpeg` и добавьте в PATH.

Пример команд для диагностики:

```bash
# Проверить токен
curl -s "https://api.telegram.org/bot$TELEGRAM_TOKEN/getMe" | jq

# Проверить что ffmpeg доступен
ffmpeg -version
```

## Разработка и тесты

- Код организован в модуль `text_toxic_bot`. Для локальной разработки рекомендуется запускать бот под отладчиком и прогонять быстрые unit‑тесты для `inference.py`.
- Тяжёлые операции выполняйте в тестах аккуратно (модель Whisper/BiLSTM можно мокать или использовать лёгкие тестовые файлы).

## Contributor Guide

- Откройте issue перед крупными изменениями архитектуры
- Пишите небольшие, проверяемые PR. Документируйте изменения в `README.md` и обновляйте `requirements.txt`.

## Лицензия

Проект не содержит явной лицензии. Добавьте `LICENSE` файл, если вы хотите открыть исходники под конкретной лицензией (MIT, Apache2 и т.д.).

---

Если хотите, я могу:
- обновить `requirements.txt` и зафиксировать версии,
- добавить `text_toxic_bot/.gitignore` и удалить `.env` из индекса,
- или применить замену вывода заголовков на "токсично"/"не токсично" прямо в `bot.py`.

Сообщите, что сделать дальше.
# VoxToxic (VoxToxic - voice toxicity detector)

Краткое описание

VoxToxic — лёгкий Telegram-бот для детекции токсичности в голосовых сообщениях. Пользователь отправляет голос — бот транскрибирует (Whisper), показывает расшифровку и даёт результат токсичности с вероятностью.

Основные возможности

- Выбор модели: `logreg`, `svm`, `voting`, `bilstm`
- Транскрибация с помощью Whisper (локально)

Структура взаимодействия

1. /start — приветствие + меню с кнопками:
   - Выбрать модель (переход в список моделей)
   - Помощь (описание работы)
   - Описание используемых моделей

2. Голосовое сообщение
   - Бот скачивает голосовой файл (ogg/opus), конвертирует в wav через `ffmpeg`
   - Whisper транскрибирует аудио в текст (русский язык)
   - Если транскрибация включена — бот отправляет расшифровку
   - Если выбран постоянный режим модели — бот сразу запускает `predict_toxicity(text, model)` и отправляет результат
   - Если выбран режим "по запросу" — бот предлагает выбрать модель via inline-клавиатура и выполняет `predict_toxicity` после выбора*
   - В ответе: метка и вероятность (в процентах).

3. Настройка окружения (локально)

1. Создайте виртуальное окружение и активируйте его

2. Установите зависимости (пример):

```bash
pip install -r requirements.txt
# Примечание: рекомендую установить python-telegram-bot v13.x для совместимости с этим кодом.
# Убедитесь, что ffmpeg доступен в PATH (ffmpeg -version)
```

3. Установите `ffmpeg` и убедитесь, что он доступен из консоли (ffmpeg -version)

4. Создайте `.env` в корне `VoxToxic` и добавьте токен:

```
TELEGRAM_TOKEN=ваш_токен
```

5. Запуск бота (polling):

```bash
python -m text_toxic_bot.bot
```

Функции безопасности и примечания

- Не коммитьте `.env` с токеном в репозиторий
- Whisper локальный может потребовать GPU или много времени на CPU; при проблемах можно использовать OpenAI Whisper API или другие STT


Дальше

Я начну с реализации скелета бота (`bot.py`) с меню, выбором модели и переключателем транскрибации.

Если у вас есть дополнения — напишите; иначе я перейду к следующему шагу: создать `bot.py` с использованием python-telegram-bot и интеграцией Whisper и `inference.predict_toxicity`.
