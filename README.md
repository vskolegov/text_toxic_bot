# text_toxic_bot — Telegram-бот для детекции токсичности речи

## Описание

Проект реализует два способа инференса токсичности речи:
- классические модели (TF‑IDF + LogisticRegression/SVM и ансамбль)
- BiLSTM (PyTorch checkpoint)

Бот принимает голосовые сообщения, конвертирует их в WAV (через ffmpeg), запускает локальную модель распознавания речи (Whisper) и затем передаёт текст на предсказание модели токсичности. Также есть локальный HTTP endpoint /predict (FastAPI) для интеграции. 

## Структура

- text_toxic_bot: основной пакет с ботом, инференсом и моделями
  - text_toxic_bot/bot.py — асинхронный Telegram‑бот (PTB v20+)
  - text_toxic_bot/inference.py — точка входа для predict_toxicity(text, model_type)
  - text_toxic_bot/models/ — локальные файлы моделей (пиклы, .pth, словари)
  - text_toxic_bot/data/ — вспомогательные JSON (пользователи, настройки)
  - text_toxic_bot/requirements.txt — зависимости

## Требования

- Python 3.10+
- ffmpeg
- ~ 1 Гб ОЗУ (под Whisper и сессии)
- python зависимости

## Конфигурация

1. Создайте файл .env в каталоге text_toxic_bot/ с переменной TELEGRAM_TOKEN:
TELEGRAM_TOKEN=123456:ABC-DEF...

2. Если используете прокси, экспортируйте переменные окружения HTTP_PROXY / HTTPS_PROXY или настройте систему прокси отдельно.

3. добавьте исходники обученных можелей .pkl в папку models

## Запуск

1) Запуск бота (поднимает также все необходимые сервисы)
python -m text_toxic_bot.bot

Бот использует асинхронные обработчики и для тяжёлых задач (Whisper, инференс BiLSTM, ffmpeg) переводит работу в run_in_executor, чтобы не блокировать loop.

2) Запуск FastAPI endpoint (для интеграций)
uvicorn text_toxic_bot.api:app --reload --port 8000

Эндпойнт /predict принимает JSON: { "text": "...", "model": "classic" } и возвращает результат предсказания.

## Использование бота

- /start — стартовое сообщение и клавиатура
- Выбор модели — кнопки на клавиатуре (`Ансамбль`, BiLSTM, Classic, и т.д.)
- Отправьте голосовое сообщение — бот транскрибирует его и вернёт метку и вероятности. Метка выводится текстом: "токсично" / "не токсично".

Клавиатура также содержит кнопку "Инфо моделей" — показывает краткую информацию о загруженных моделях и их источниках.

Есть возможность выбрать режим работы: предвыбранная модель для всех последующих предсказаний или выбор модели непосредственно после отправки сообщений (паралельрый процесс). 

Бот запоминает пользователей, а также выбранный ими режим использования и модель при последующих развертываниях. 

## Модели

Модели лежат в text_toxic_bot/models/:

- classic: tfidf.pkl, model_logreg.pkl, model_svm.pkl
- bilstm: correct_bilstm.pth, word2idx.pkl

Модели загружаются при первом вызове predict_toxicity первого пользователя, также как и Whisper.

При замене моделей нужно убедится что форматы совпадают и что используемые версии библиотек (scikit-learn, torch) совместимы с файлами.

## Возможные проблемы при развертывании

- Ошибка с инициализацией PTB ExtBot / сетевые таймауты: проверьте корректность TELEGRAM_TOKEN и настройки прокси/фаервола.
- Ошибки при распаковке pickle (scikit-learn): возможно несоответствие версии scikit-learn при создании и загрузке модели. Попробуйте установить ту же версию, что и использовавшаяся при тренировке.
- Whisper скачивает веса при первом запуске — убедитесь, что есть место и стабильное соединение.
- ffmpeg не найден: установите ffmpeg и добавьте в PATH.

Пример команд для диагностики:
### Проверить токен
curl -s "https://api.telegram.org/bot$TELEGRAM_TOKEN/getMe" | jq

### Проверить что ffmpeg доступен
ffmpeg -version

## Разработка и тесты

- Код организован в модуль text_toxic_bot. Для локальной разработки рекомендуется запускать бот под отладчиком и прогонять быстрые unit‑тесты для inference.py.
- Тяжёлые операции выполняйте в тестах аккуратно (модель Whisper/BiLSTM можно мокать или использовать лёгкие тестовые файлы)
